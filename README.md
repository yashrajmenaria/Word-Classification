# Word-Classification-through-word-Embedding

### Project Overview:

This project explores the use of word embeddings to classify words and plot the similarity between them. Word embeddings are a powerful tool in natural language processing (NLP) that represent words in continuous vector space, capturing semantic relationships between them. The aim is to leverage these embeddings to develop a classification model that can accurately categorize words based on their meanings.

### Objectives:

To understand and implement word embeddings for representing words in vector space.
To develop a machine learning model for classifying words into different categories.
To evaluate the performance of the model using appropriate metrics.

### Dataset: 

The future king is the prince

Daughter is the princess

Son is the prince

Only a man can be a king

Only a woman can be a queen

The princess will be a queen

Queen and king rule the realm

The prince is a strong man

The princess is a beautiful woman

The royal family is the king and queen and their children

Prince is only a boy now

A boy will be a man

### Description: 

The dataset contains 12 simple sentences containing words.

### Methodology:

**Data Preprocessing:**

Cleaning and preprocessing the text data.

Generating word embeddings for the words in the dataset.

**Model Development:**

Selection of a suitable machine learning model.

Training the model using the word embeddings as input features.

**Evaluation:**

Evaluating the model's performance by plotting the relationship on a graph.

### Conclusion:

The project demonstrates the effectiveness of word embeddings in capturing semantic relationships between words and their application in word classification tasks. The developed model shows promising results and can be further improved with more sophisticated techniques.
